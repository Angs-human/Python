{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7299a1-1c6c-41d9-8f09-165a949b7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc2cf41-2b14-421d-bbbc-1909b6d62d61",
   "metadata": {},
   "source": [
    "# Q1. Write a code to print the data present in the second row of the dataframe, df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7ec323-0b59-4f8f-9845-83e2e443f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the data present in the second row of the dataframe\n",
    "second_row = df.iloc[1]\n",
    "print(second_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e4d1bf-9e42-4afc-86af-e1d3ce3f60c6",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01058b-81bb-4fad-b382-46cc6f7f66df",
   "metadata": {},
   "source": [
    "In a `pandas.DataFrame`, `loc` and `iloc` are both used to access data, but they differ in how they reference the rows and columns:\n",
    "\n",
    "### `loc`:\n",
    "- **Label-based indexing**: `loc` is used to access rows and columns by their labels (index names).\n",
    "- **Inclusive slicing**: When slicing, both the start and the end labels are included.\n",
    "- **Works with boolean arrays**: You can use a boolean array to filter data.\n",
    "- **Example usage**:\n",
    "  ```python\n",
    "  df.loc[2, 'course_name']  # Accesses the row with index label 2 and column 'course_name'\n",
    "  ```\n",
    "\n",
    "### `iloc`:\n",
    "- **Integer-based indexing**: `iloc` is used to access rows and columns by their integer positions (0-based index).\n",
    "- **Exclusive slicing**: When slicing, the start index is included, but the end index is excluded, similar to standard Python slicing.\n",
    "- **Does not work with labels**: Only integer positions are valid, not index labels.\n",
    "- **Example usage**:\n",
    "  ```python\n",
    "  df.iloc[2, 1]  # Accesses the third row and second column by integer positions\n",
    "  ```\n",
    "\n",
    "### Summary:\n",
    "- **`loc`**: Use it when you know the labels (names) of rows or columns you want to access.\n",
    "- **`iloc`**: Use it when you know the positions (integers) of rows or columns you want to access.\n",
    "\n",
    "This distinction allows for flexible data selection depending on how the DataFrame is structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e79d4-e625-4053-8a8c-82d78cfe7218",
   "metadata": {},
   "source": [
    "# Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9acb74a-7292-4ae3-ae70-93d056d9ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a18f239-200f-4dd5-a82f-eb9515240875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "3     Data Engineer         4\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1084d4af-cf2d-41ea-8055-6f75cdacd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d12996-f681-408d-9ed8-8d7934f3b12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940853</td>\n",
       "      <td>0.733388</td>\n",
       "      <td>0.866951</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>0.311522</td>\n",
       "      <td>0.479485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.797485</td>\n",
       "      <td>0.627487</td>\n",
       "      <td>0.105272</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.794029</td>\n",
       "      <td>0.318958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336105</td>\n",
       "      <td>0.105992</td>\n",
       "      <td>0.675179</td>\n",
       "      <td>0.529557</td>\n",
       "      <td>0.666316</td>\n",
       "      <td>0.849354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.972096</td>\n",
       "      <td>0.313713</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>0.440268</td>\n",
       "      <td>0.717937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.076348</td>\n",
       "      <td>0.254697</td>\n",
       "      <td>0.555401</td>\n",
       "      <td>0.639952</td>\n",
       "      <td>0.043196</td>\n",
       "      <td>0.525776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.182907</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>0.715888</td>\n",
       "      <td>0.650397</td>\n",
       "      <td>0.316425</td>\n",
       "      <td>0.431680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.940853  0.733388  0.866951  0.500206  0.311522  0.479485\n",
       "2  0.797485  0.627487  0.105272  0.996000  0.794029  0.318958\n",
       "3  0.336105  0.105992  0.675179  0.529557  0.666316  0.849354\n",
       "4  0.972096  0.313713  0.880299  0.482422  0.440268  0.717937\n",
       "5  0.076348  0.254697  0.555401  0.639952  0.043196  0.525776\n",
       "6  0.182907  0.700479  0.715888  0.650397  0.316425  0.431680"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20d666-808f-4de9-bfc8-b2a08602fc0b",
   "metadata": {},
   "source": [
    "# Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "## (i) mean of each and every column present in the dataframe.\n",
    "## (ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8df35d-9ead-4420-84db-d2d8012c2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      " column_1    0.550966\n",
      "column_2    0.455959\n",
      "column_3    0.633165\n",
      "column_4    0.633089\n",
      "column_5    0.428626\n",
      "column_6    0.553865\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mean of each column\n",
    "mean_of_columns = df1.mean()\n",
    "print(\"Mean of each column:\\n\", mean_of_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65457239-68bf-4306-95b5-e697b2556d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of column_2: 0.26434663409105685\n"
     ]
    }
   ],
   "source": [
    "# Standard deviation of 'column_2'\n",
    "std_column_2 = df1['column_2'].std()\n",
    "print(\"Standard deviation of column_2:\", std_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b15e7e-46ae-4bdc-801f-617b78b33ae8",
   "metadata": {},
   "source": [
    "# Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2.If you are getting errors in executing it then explain why.\n",
    "## [Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e24869c-a44c-45bd-8b66-3fc46bc99ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column_1      column_2  column_3  column_4  column_5  column_6\n",
      "1  0.940853      0.733388  0.866951  0.500206  0.311522  0.479485\n",
      "2  0.797485  string_value  0.105272  0.996000  0.794029  0.318958\n",
      "3  0.336105      0.105992  0.675179  0.529557  0.666316  0.849354\n",
      "4  0.972096      0.313713  0.880299  0.482422  0.440268  0.717937\n",
      "5  0.076348      0.254697  0.555401  0.639952  0.043196  0.525776\n",
      "6  0.182907      0.700479  0.715888  0.650397  0.316425  0.431680\n"
     ]
    }
   ],
   "source": [
    "# Replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'string_value'\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb15496-c831-42cc-9078-f50bfbcc27c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Attempt to calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of column_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Attempt to calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of column_2:\", mean_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9dcaf-3e53-4e50-a109-0627c5c8029e",
   "metadata": {},
   "source": [
    "Let's work through the process of replacing data in the DataFrame and then attempting to calculate the mean of the column.\n",
    "\n",
    "### Step 1: Replace the Data in the Second Row of `column_2`\n",
    "You can replace the data in the second row of `column_2` with a string value using `df1.loc[]`.\n",
    "\n",
    "```python\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'string_value'\n",
    "print(df1)\n",
    "```\n",
    "\n",
    "### Step 2: Attempt to Calculate the Mean of `column_2`\n",
    "After replacing the numeric value with a string, let's try to calculate the mean of `column_2`.\n",
    "\n",
    "```python\n",
    "# Attempt to calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of column_2:\", mean_column_2)\n",
    "```\n",
    "\n",
    "### Explanation of Errors:\n",
    "When you try to calculate the mean of `column_2` after replacing a numeric value with a string, you will likely encounter an error. The reason for this is:\n",
    "\n",
    "- **Data Type Incompatibility:** The `mean()` function in pandas expects all values in the column to be numeric. If a column contains a non-numeric value, such as a string, pandas will not be able to perform the mathematical operation to calculate the mean, resulting in a `TypeError`.\n",
    "\n",
    "Here’s what the error might look like:\n",
    "\n",
    "```python\n",
    "TypeError: could not convert string to float: 'string_value'\n",
    "```\n",
    "\n",
    "### How to Handle the Situation:\n",
    "- **Ensure All Values Are Numeric:** If you need to calculate the mean, make sure that all the values in the column are numeric. If a non-numeric value is present, you could either remove it or replace it with a numeric value before calculating the mean.\n",
    "- **Convert Back to Numeric:** If possible, you can try to convert the column back to a numeric type using `pd.to_numeric()` with error handling.\n",
    "\n",
    "```python\n",
    "# Convert the column back to numeric, coercing errors to NaN\n",
    "df1['column_2'] = pd.to_numeric(df1['column_2'], errors='coerce')\n",
    "\n",
    "# Now calculate the mean, ignoring NaN values\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of column_2 after conversion:\", mean_column_2)\n",
    "```\n",
    "\n",
    "This approach will replace the non-numeric value with `NaN` and then calculate the mean, ignoring the `NaN`.\n",
    "\n",
    "Would you like to proceed with this, or do you need further explanation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab4431f-be35-4d39-931c-e161f0b74510",
   "metadata": {},
   "source": [
    "# Q6. What do you understand about the windows function in pandas and list the types of windows functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe6188-59f6-4546-beed-22ca0a5db2b2",
   "metadata": {},
   "source": [
    "The **window functions** in pandas are powerful tools that allow for performing calculations across a sliding window of data, rather than across the entire dataset. These functions are particularly useful for time series data analysis, where you might want to calculate rolling averages, cumulative sums, or other statistical measures over a specified window of consecutive data points.\n",
    "\n",
    "### What Are Window Functions in Pandas?\n",
    "\n",
    "Window functions operate by defining a fixed-size window that slides over the dataset. For each position of the window, a calculation is performed on the data within that window. The result is an output series of the same length as the original series, with each element representing the calculation applied to the window that ends at that point.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Window Size**: The number of observations used in each calculation.\n",
    "- **Centering**: Whether the window is centered around the current observation or starts at the current observation and goes back or forward.\n",
    "- **Min Periods**: The minimum number of observations in the window required to perform a calculation.\n",
    "- **Types of Window Functions**: Depending on how the window is defined, you can have different types of window functions.\n",
    "\n",
    "### Types of Window Functions:\n",
    "\n",
    "1. **Rolling Window Functions (`.rolling()`)**:\n",
    "   - **Description**: Performs calculations over a sliding window of a fixed size.\n",
    "   - **Common Uses**: Rolling averages, rolling sums, rolling standard deviations, etc.\n",
    "   - **Example**: \n",
    "     ```python\n",
    "     df['column'].rolling(window=3).mean()  # Rolling mean with a window of 3\n",
    "     ```\n",
    "\n",
    "2. **Expanding Window Functions (`.expanding()`)**:\n",
    "   - **Description**: Expanding windows start at the first observation and grow with each subsequent observation, calculating statistics for all data up to the current point.\n",
    "   - **Common Uses**: Cumulative sum, cumulative mean, etc.\n",
    "   - **Example**: \n",
    "     ```python\n",
    "     df['column'].expanding().mean()  # Expanding mean\n",
    "     ```\n",
    "\n",
    "3. **Exponentially Weighted Windows (`.ewm()`)**:\n",
    "   - **Description**: Applies an exponentially decreasing weight to older observations. This is useful when more recent observations should have more influence on the calculation than older ones.\n",
    "   - **Common Uses**: Exponentially weighted moving averages.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     df['column'].ewm(span=3).mean()  # Exponentially weighted moving average with a span of 3\n",
    "     ```\n",
    "\n",
    "4. **Cumulative Functions**:\n",
    "   - **Description**: Calculates a cumulative statistic from the beginning of the series up to the current observation.\n",
    "   - **Common Uses**: Cumulative sum, cumulative product.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     df['column'].cumsum()  # Cumulative sum\n",
    "     ```\n",
    "\n",
    "### Summary:\n",
    "- **Rolling Functions** are useful for analyzing trends over a moving window of data points.\n",
    "- **Expanding Functions** allow you to analyze how metrics evolve as more data becomes available.\n",
    "- **Exponentially Weighted Functions** give more importance to recent observations in the data series.\n",
    "- **Cumulative Functions** provide a running total or product of the data points up to the current position.\n",
    "\n",
    "Each of these window functions can be customized with parameters like window size, min periods, and other options to suit specific analytical needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c78e8-2f69-435f-9799-21d603810fe7",
   "metadata": {},
   "source": [
    "# Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "## [Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6ca7ee-9091-48fe-925c-88d9d1494b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August, 2024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = pd.Timestamp.now()\n",
    "\n",
    "# Extract and print only the current month and year\n",
    "current_month_year = current_datetime.strftime('%B, %Y')\n",
    "print(current_month_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b29902-648b-4626-9401-48ddd173a9e2",
   "metadata": {},
   "source": [
    "# Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7fb6b3b-44e9-45fe-9ac2-7c016aab2ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2002-07-29\n",
      "Enter the second date (YYYY-MM-DD):  2004-01-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between dates: 528 days, 0 hours, and 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_time_difference(date1_str, date2_str):\n",
    "    # Convert input strings to pandas datetime objects\n",
    "    date1 = pd.Timestamp(date1_str)\n",
    "    date2 = pd.Timestamp(date2_str)\n",
    "    \n",
    "    # Calculate the time difference\n",
    "    time_difference = date2 - date1\n",
    "    \n",
    "    # Extract days, hours, and minutes from the timedelta object\n",
    "    days = time_difference.days\n",
    "    hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes, _ = divmod(remainder, 60)\n",
    "    \n",
    "    return days, hours, minutes\n",
    "\n",
    "def main():\n",
    "    # Prompt user to enter two dates\n",
    "    date1_str = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "    date2_str = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "    \n",
    "    # Calculate time difference\n",
    "    days, hours, minutes = calculate_time_difference(date1_str, date2_str)\n",
    "    \n",
    "    # Display the result\n",
    "    print(f\"Difference between dates: {days} days, {hours} hours, and {minutes} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce75c05-73fa-4042-9e82-3128559950c7",
   "metadata": {},
   "source": [
    "# Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a4bce-3db6-4a1c-9749-013924e7e44d",
   "metadata": {},
   "source": [
    "### Q8: Python Program to Calculate Mean, Median, and Mode of Test Scores\n",
    "\n",
    "Here's a Python program that accomplishes the task of reading a CSV file containing student test scores, calculating the mean, median, and mode, and displaying these statistics in a table.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_statistics(file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'Test Score' column exists\n",
    "    if 'Test Score' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain a 'Test Score' column.\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = df['Test Score'].mean()\n",
    "    median = df['Test Score'].median()\n",
    "    mode = df['Test Score'].mode().tolist()\n",
    "    \n",
    "    # Display results in a table format\n",
    "    print(\"+-----------+--------+\")\n",
    "    print(\"| Statistic | Value  |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "    print(f\"| Mean      | {mean:.1f}   |\")\n",
    "    print(f\"| Median    | {median}   |\")\n",
    "    mode_str = ', '.join(map(str, mode))\n",
    "    print(f\"| Mode      | {mode_str} |\")\n",
    "    print(\"+-----------+--------+\")\n",
    "\n",
    "def main():\n",
    "    # Prompt user for file path\n",
    "    file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    calculate_statistics(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Read CSV File**: The `pd.read_csv(file_path)` reads the CSV file into a DataFrame.\n",
    "2. **Calculate Statistics**: Compute the mean, median, and mode of the 'Test Score' column.\n",
    "   - **Mean**: Average of test scores.\n",
    "   - **Median**: Middle value when scores are sorted.\n",
    "   - **Mode**: Most frequently occurring test scores (can be multiple values).\n",
    "3. **Display Results**: The results are displayed in a formatted table.\n",
    "\n",
    "### Q9: Python Program to Convert Column to Categorical Data Type and Display Sorted Data\n",
    "\n",
    "Here’s a Python program that reads a CSV file, converts a specified column to a categorical data type with a defined category order, and displays the sorted data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def process_categorical_data(file_path, column_name, category_order):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"The CSV file must contain a '{column_name}' column.\")\n",
    "    \n",
    "    # Convert the specified column to a categorical data type with the given order\n",
    "    categories = category_order.split(',')\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=categories, ordered=True)\n",
    "    \n",
    "    # Sort the DataFrame by the categorical column\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    \n",
    "    # Display the sorted DataFrame\n",
    "    print(f\"Sorted data by column '{column_name}':\")\n",
    "    print(sorted_df)\n",
    "\n",
    "def main():\n",
    "    # Prompt user for file path, column name, and category order\n",
    "    file_path = input(\"Enter the file path of the CSV file: \")\n",
    "    column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "    category_order = input(\"Enter the category order, separated by commas: \")\n",
    "    \n",
    "    # Process and display sorted data\n",
    "    process_categorical_data(file_path, column_name, category_order)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Read CSV File**: The `pd.read_csv(file_path)` reads the CSV file into a DataFrame.\n",
    "2. **Convert to Categorical**: The specified column is converted to a categorical data type with the provided category order.\n",
    "3. **Sort Data**: The DataFrame is sorted based on the categorical column.\n",
    "4. **Display Sorted Data**: The sorted DataFrame is displayed.\n",
    "\n",
    "These programs allow you to handle and analyze data efficiently using pandas. If you need further adjustments or have additional questions, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad66b823-43f1-41c8-a10e-8a892d210952",
   "metadata": {},
   "source": [
    "# Q10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a786e6-15e9-43a1-8c18-7e6a9d511bba",
   "metadata": {},
   "source": [
    "To create a Python program that reads a CSV file containing sales data and visualizes it using a stacked bar chart, you can use `pandas` for data manipulation and `matplotlib` for plotting. Below is a complete program to achieve this.\n",
    "\n",
    "### Python Program for Stacked Bar Chart\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stacked_bar_chart(file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure required columns are present\n",
    "    if 'Date' not in df.columns or 'Product Category' not in df.columns or 'Sales' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain 'Date', 'Product Category', and 'Sales' columns.\")\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Pivot the DataFrame to get dates as index, product categories as columns, and sales as values\n",
    "    df_pivot = df.pivot_table(index='Date', columns='Product Category', values='Sales', aggfunc='sum', fill_value=0)\n",
    "    \n",
    "    # Plot the stacked bar chart\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True, figsize=(10, 7))\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Sales by Product Category Over Time')\n",
    "    plt.legend(title='Product Category')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Prompt user for file path\n",
    "    file_path = input(\"Enter the file path of the CSV file containing sales data: \")\n",
    "    \n",
    "    # Plot the stacked bar chart\n",
    "    plot_stacked_bar_chart(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Read CSV File**:\n",
    "   - The `pd.read_csv(file_path)` function reads the CSV file into a DataFrame.\n",
    "   - The program checks for the required columns: 'Date', 'Product Category', and 'Sales'.\n",
    "\n",
    "2. **Prepare Data**:\n",
    "   - **Convert 'Date'**: The 'Date' column is converted to a datetime object for proper time series handling.\n",
    "   - **Pivot Table**: The `pivot_table` function is used to rearrange the DataFrame so that dates are indices, product categories are columns, and sales are values. This creates a DataFrame suitable for a stacked bar chart.\n",
    "\n",
    "3. **Plot Stacked Bar Chart**:\n",
    "   - The `plot` method with `kind='bar'` and `stacked=True` creates a stacked bar chart.\n",
    "   - **Labels and Title**: Axis labels and a title are added for clarity.\n",
    "   - **Display Chart**: `plt.show()` renders the chart.\n",
    "\n",
    "### Example CSV Format:\n",
    "\n",
    "The CSV file should be structured like this:\n",
    "\n",
    "```\n",
    "Date,Product Category,Sales\n",
    "2024-01-01,Electronics,100\n",
    "2024-01-01,Clothing,150\n",
    "2024-02-01,Electronics,120\n",
    "2024-02-01,Clothing,180\n",
    "...\n",
    "```\n",
    "\n",
    "Each row represents a sale with a date, product category, and sales amount.\n",
    "\n",
    "### Requirements:\n",
    "- **Pandas**: For data manipulation.\n",
    "- **Matplotlib**: For plotting the chart.\n",
    "\n",
    "Install these libraries using pip if you haven't already:\n",
    "\n",
    "```bash\n",
    "pip install pandas matplotlib\n",
    "```\n",
    "\n",
    "This program will help visualize how different product categories contribute to sales over time, providing valuable insights into sales trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074ae1f-7c6a-4370-b190-a81ffd2d904e",
   "metadata": {},
   "source": [
    "# Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and displays the results in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81bb19-71f7-43a5-ac3d-8d80b020526a",
   "metadata": {},
   "source": [
    "To write a Python program that reads a CSV file containing student data, calculates the mean, median, and mode of the test scores, and displays the results in a table, you can use `pandas` for data manipulation and calculations, and `tabulate` to format the output as a table.\n",
    "\n",
    "Here's how you can do it:\n",
    "\n",
    "### Python Program\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def calculate_statistics(file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'Test Score' column exists\n",
    "    if 'Test Score' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain a 'Test Score' column.\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = df['Test Score'].mean()\n",
    "    median = df['Test Score'].median()\n",
    "    mode = df['Test Score'].mode().tolist()\n",
    "    \n",
    "    # Prepare data for the table\n",
    "    table_data = [\n",
    "        [\"Mean\", f\"{mean:.2f}\"],\n",
    "        [\"Median\", f\"{median:.2f}\"],\n",
    "        [\"Mode\", ', '.join(map(str, mode))]\n",
    "    ]\n",
    "    \n",
    "    # Display results in a table format using tabulate\n",
    "    print(tabulate(table_data, headers=[\"Statistic\", \"Value\"], tablefmt=\"grid\"))\n",
    "\n",
    "def main():\n",
    "    # Prompt user for file path\n",
    "    file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    calculate_statistics(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Read CSV File**:\n",
    "   - The `pd.read_csv(file_path)` function reads the CSV file into a DataFrame.\n",
    "   - The program checks if the 'Test Score' column exists in the DataFrame.\n",
    "\n",
    "2. **Calculate Statistics**:\n",
    "   - **Mean**: Average of the test scores.\n",
    "   - **Median**: Middle value of the sorted test scores.\n",
    "   - **Mode**: Most frequently occurring test scores. If there are multiple modes, all are included.\n",
    "\n",
    "3. **Prepare Data for Table**:\n",
    "   - `table_data` is a list of lists where each inner list represents a row in the table. The format includes the statistic name and its value.\n",
    "\n",
    "4. **Display Results in a Table**:\n",
    "   - The `tabulate` function from the `tabulate` library formats the data into a nicely aligned table. You need to install the `tabulate` library if it's not already installed:\n",
    "\n",
    "   ```bash\n",
    "   pip install tabulate\n",
    "   ```\n",
    "\n",
    "5. **Main Function**:\n",
    "   - Prompts the user to enter the file path.\n",
    "   - Calls `calculate_statistics()` to read the file, compute statistics, and display them in a table.\n",
    "\n",
    "### Example CSV Format:\n",
    "\n",
    "The CSV file should be structured like this:\n",
    "\n",
    "```\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "```\n",
    "\n",
    "Each row represents a student's ID and their test score.\n",
    "\n",
    "This program will help you analyze the distribution of test scores and present the results in a clear and structured format. If you have further questions or need additional features, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
